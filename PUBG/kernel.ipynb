{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "#Imports\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc, sys\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = '/home/lgriffin/Documents/Jupyter/Kaggle/Data/PUBG/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataframe, target = 'winPlacePerc'):\n",
    "    \n",
    "    #get a list of featuress, remove the uncessary ones\n",
    "    features = list(dataframe.columns)\n",
    "    features.remove(\"Id\")\n",
    "    features.remove(\"matchId\")\n",
    "    features.remove(\"groupId\")\n",
    "    features.remove(\"matchType\")\n",
    "    features.remove(\"walkDistance\")\n",
    "    features.remove(\"kills\")\n",
    "    \n",
    "    if target is not None:\n",
    "        features.remove(target)\n",
    "    \n",
    "    #Add some new features\n",
    "    dataframe.loc[:,'avgVelocity'] = dataframe.loc[:,'walkDistance']/dataframe.loc[:,'matchDuration']\n",
    "    dataframe.loc[:,'headshotRate'] = dataframe.loc[:,'kills']/dataframe.loc[:,'headshotKills']\n",
    "    dataframe.loc[:,'killStreakRate'] = dataframe.loc[:,'killStreaks']/dataframe.loc[:,'kills']\n",
    "    dataframe.loc[:,'kills_assists'] = dataframe.loc[:,'assists']+dataframe.loc[:,'kills']\n",
    "    \n",
    "    dataframe['headshotRate'] = dataframe['headshotRate'].apply(lambda x: 0 if x == np.inf else x)\n",
    "    dataframe['killStreakRate'] = dataframe['killStreakRate'].apply(lambda x: 0 if x == np.inf else x)\n",
    "    \n",
    "    #don't forget to fill nan's with zeros, these nan's are due to headshotRate being kills/headshots\n",
    "    #dataframe.fillna(0)\n",
    "    \n",
    "    #Add these new features to the feature list\n",
    "    features.append('avgVelocity')\n",
    "    features.append('killStreakRate')\n",
    "    features.append('headshotRate')\n",
    "    features.append('kills_assists')\n",
    "    \n",
    "    #Get the group means and rank them according to match\n",
    "    #also get the target values\n",
    "    print(\"Get group mean feature\")\n",
    "    grouped = dataframe.groupby(['matchId','groupId'])\n",
    "    \n",
    "    if target is not None:\n",
    "        y = grouped[target].agg('mean').reset_index()\n",
    "    else:\n",
    "        y = None\n",
    "    \n",
    "    agg = grouped[features].agg('mean')\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    \n",
    "    df_out = agg.reset_index()[['matchId','groupId']]\n",
    "    \n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "        \n",
    "    print(\"Get group max feature\")\n",
    "    agg = dataframe.groupby(['matchId','groupId'])[features].agg('max')\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    print(\"Get group min feature\")\n",
    "    agg = dataframe.groupby(['matchId','groupId'])[features].agg('min')\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    print(\"Get match mean feature\")\n",
    "    agg = dataframe.groupby(['matchId'])[features].agg('mean').reset_index()\n",
    "    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n",
    "    \n",
    "    print(\"get match size feature\")\n",
    "    agg = dataframe.groupby(['matchId']).size().reset_index(name='match_size')\n",
    "    df_out = df_out.merge(agg, how='left', on=['matchId'])\n",
    "    \n",
    "    #Merge these new features with the original features\n",
    "    if target is not None:\n",
    "        df_out = df_out.merge(y, suffixes=[\"\", target], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    del agg, agg_rank\n",
    "    gc.collect()\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale down the features according to number of deviations away from the mean\n",
    "def scale_features(dataframe):\n",
    "    \n",
    "    features = ['assists_mean', 'boosts_mean',\n",
    "       'damageDealt_mean', 'DBNOs_mean', 'headshotKills_mean',\n",
    "       'heals_mean', 'killPlace_mean', 'killPoints_mean',\n",
    "       'killStreaks_mean', 'longestKill_mean', 'matchDuration_mean',\n",
    "       'maxPlace_mean', 'numGroups_mean', 'rankPoints_mean',\n",
    "       'revives_mean', 'rideDistance_mean', 'roadKills_mean',\n",
    "       'swimDistance_mean', 'teamKills_mean', 'vehicleDestroys_mean',\n",
    "       'weaponsAcquired_mean', 'winPoints_mean', 'avgVelocity_mean',\n",
    "       'killStreakRate_mean', 'headshotRate_mean', 'kills_assists_mean',\n",
    "       'assists_max', 'boosts_max',\n",
    "       'damageDealt_max', 'DBNOs_max', 'headshotKills_max', 'heals_max',\n",
    "       'killPlace_max', 'killPoints_max', 'killStreaks_max',\n",
    "       'longestKill_max', 'matchDuration_max', 'maxPlace_max',\n",
    "       'numGroups_max', 'rankPoints_max', 'revives_max',\n",
    "       'rideDistance_max', 'roadKills_max', 'swimDistance_max',\n",
    "       'teamKills_max', 'vehicleDestroys_max', 'weaponsAcquired_max',\n",
    "       'winPoints_max', 'avgVelocity_max', 'killStreakRate_max',\n",
    "       'headshotRate_max', 'kills_assists_max', \n",
    "       'assists_min', 'boosts_min',\n",
    "       'damageDealt_min', 'DBNOs_min', 'headshotKills_min', 'heals_min',\n",
    "       'killPlace_min', 'killPoints_min', 'killStreaks_min',\n",
    "       'longestKill_min', 'matchDuration_min', 'maxPlace_min',\n",
    "       'numGroups_min', 'rankPoints_min', 'revives_min',\n",
    "       'rideDistance_min', 'roadKills_min', 'swimDistance_min',\n",
    "       'teamKills_min', 'vehicleDestroys_min', 'weaponsAcquired_min',\n",
    "       'winPoints_min', 'avgVelocity_min', 'killStreakRate_min',\n",
    "       'headshotRate_min', 'kills_assists_min',\n",
    "       'assists', 'boosts', 'damageDealt',\n",
    "       'DBNOs', 'headshotKills', 'heals', 'killPlace', 'killPoints',\n",
    "       'killStreaks', 'longestKill', 'matchDuration', 'maxPlace',\n",
    "       'numGroups', 'rankPoints', 'revives', 'rideDistance', 'roadKills',\n",
    "       'swimDistance', 'teamKills', 'vehicleDestroys', 'weaponsAcquired',\n",
    "       'winPoints', 'avgVelocity', 'killStreakRate', 'headshotRate',\n",
    "       'kills_assists']\n",
    "    \n",
    "    dataframe[features] = dataframe[features].apply(lambda x: (x - x.mean())/(x.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_train(directory, target='winPlacePerc'):\n",
    "    \n",
    "    train = pd.read_csv(directory+'train_V2.csv')\n",
    "    train.drop(2744604, inplace=True)\n",
    "    train = preprocess_data(train, target)\n",
    "    scale_features(train)\n",
    "    train = train.fillna(0)\n",
    "    \n",
    "    features = list(train.columns.values)\n",
    "    features.remove(\"matchId\")\n",
    "    features.remove(\"groupId\")\n",
    "    features.remove(target)\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return train[features].values, train[target].values, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_test(directory):\n",
    "    \n",
    "    test = pd.read_csv(directory+'test_V2.csv')\n",
    "    test = preprocess_data(test, None)\n",
    "    scale_features(test)\n",
    "    test = test.fillna(0)\n",
    "    \n",
    "    features = list(train.columns.values)\n",
    "    features.remove(\"matchId\")\n",
    "    features.remove(\"groupId\")\n",
    "    features.remove(target)\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return test[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, features = prep_train(INPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- Model\n",
    "model = NuSVR(kernel='rbf', C=0.9, nu=1)\n",
    "\n",
    "#Use a simple 10% hold out for validation\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X, \n",
    "                                                      y, test_size=0.10)  \n",
    "\n",
    "del X, y\n",
    "gc.collect()\n",
    "\n",
    "fitted = model.fit(x_train, y_train)\n",
    "y_valid_predict = fitted.predict(x_valid)\n",
    "print('R2: ', fitted.score(x_valid, y_valid))\n",
    "print('MSE: ', mean_squared_error(y_valid, y_valid_predict))\n",
    "print('MAE: ', mean_absolute_error(y_valid, y_valid_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_name = \"svr_model.pkl\"\n",
    "with open(pkl_name, 'wb') as file:\n",
    "    pickle_model.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Prep Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = prep_test(INPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Fit Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = fitted.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
